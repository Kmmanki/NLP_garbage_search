{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawl_data_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>crawled_date</th>\n",
       "      <th>garbage</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eff83f80e8d31e18</td>\n",
       "      <td>로레알파리 엑스트라 오디네리 로즈 헤어팩 추천 리뷰</td>\n",
       "      <td>로레알파리 엑스트라 오디네리 로즈 헤어팩 리뷰 537 41% 15,000원 8,...</td>\n",
       "      <td>2021-06-02 06:17:46</td>\n",
       "      <td>가비지</td>\n",
       "      <td>로레알파리 엑스트라 오디네리 로즈 헤어팩 추천 리뷰   로레알파리 엑스트라 오디네리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a25af703642cf485</td>\n",
       "      <td>미쟝센 스타일케어 플렉서블 헤어스프레이 추천 비교</td>\n",
       "      <td>미쟝센 스타일케어 플렉서블 헤어스프레이 리뷰 20 2% 7,070원 6,900원...</td>\n",
       "      <td>2021-06-02 11:26:35</td>\n",
       "      <td>가비지</td>\n",
       "      <td>미쟝센 스타일케어 플렉서블 헤어스프레이 추천 비교   미쟝센 스타일케어 플렉서블 헤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12235a0f10526ca5</td>\n",
       "      <td>Toothcare 오랄비 전동칫솔 호환칫솔모 일반회전용 4p 제품 후기</td>\n",
       "      <td>Toothcare 오랄비 전동칫솔 호환칫솔모 일반회전용 4p 리뷰 2,941 5...</td>\n",
       "      <td>2021-06-02 22:06:58</td>\n",
       "      <td>가비지</td>\n",
       "      <td>Toothcare 오랄비 전동칫솔 호환칫솔모 일반회전용 4p 제품 후기   Toot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800a23ddb508b60</td>\n",
       "      <td>더자카 쿠션 스프라이트 실내화 리뷰</td>\n",
       "      <td>더자카 쿠션 스프라이트 실내화 리뷰 66 23% 10,600원 8,100원   ...</td>\n",
       "      <td>2021-06-03 02:05:04</td>\n",
       "      <td>가비지</td>\n",
       "      <td>더자카 쿠션 스프라이트 실내화 리뷰   더자카 쿠션 스프라이트 실내화 리뷰 66 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ec01a70a8e09cc1</td>\n",
       "      <td>메디안 치석케어 오리지널 치약 3p 가격 정리</td>\n",
       "      <td>메디안 치석케어 오리지널 치약 3p 리뷰 10,299 63% 9,900원 3,5...</td>\n",
       "      <td>2021-06-03 03:20:35</td>\n",
       "      <td>가비지</td>\n",
       "      <td>메디안 치석케어 오리지널 치약 3p 가격 정리   메디안 치석케어 오리지널 치약 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crawl_data_id                                     title  \\\n",
       "0  eff83f80e8d31e18             로레알파리 엑스트라 오디네리 로즈 헤어팩 추천 리뷰    \n",
       "1  a25af703642cf485              미쟝센 스타일케어 플렉서블 헤어스프레이 추천 비교    \n",
       "2  12235a0f10526ca5  Toothcare 오랄비 전동칫솔 호환칫솔모 일반회전용 4p 제품 후기    \n",
       "3  2800a23ddb508b60                      더자카 쿠션 스프라이트 실내화 리뷰    \n",
       "4  7ec01a70a8e09cc1                메디안 치석케어 오리지널 치약 3p 가격 정리    \n",
       "\n",
       "                                             content         crawled_date  \\\n",
       "0    로레알파리 엑스트라 오디네리 로즈 헤어팩 리뷰 537 41% 15,000원 8,...  2021-06-02 06:17:46   \n",
       "1    미쟝센 스타일케어 플렉서블 헤어스프레이 리뷰 20 2% 7,070원 6,900원...  2021-06-02 11:26:35   \n",
       "2    Toothcare 오랄비 전동칫솔 호환칫솔모 일반회전용 4p 리뷰 2,941 5...  2021-06-02 22:06:58   \n",
       "3    더자카 쿠션 스프라이트 실내화 리뷰 66 23% 10,600원 8,100원   ...  2021-06-03 02:05:04   \n",
       "4    메디안 치석케어 오리지널 치약 3p 리뷰 10,299 63% 9,900원 3,5...  2021-06-03 03:20:35   \n",
       "\n",
       "  garbage                                               text  \n",
       "0     가비지  로레알파리 엑스트라 오디네리 로즈 헤어팩 추천 리뷰   로레알파리 엑스트라 오디네리...  \n",
       "1     가비지  미쟝센 스타일케어 플렉서블 헤어스프레이 추천 비교   미쟝센 스타일케어 플렉서블 헤...  \n",
       "2     가비지  Toothcare 오랄비 전동칫솔 호환칫솔모 일반회전용 4p 제품 후기   Toot...  \n",
       "3     가비지  더자카 쿠션 스프라이트 실내화 리뷰   더자카 쿠션 스프라이트 실내화 리뷰 66 2...  \n",
       "4     가비지  메디안 치석케어 오리지널 치약 3p 가격 정리   메디안 치석케어 오리지널 치약 3...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "test_df = pd.read_excel('Training_Test.xlsx',sheet_name=2)\r\n",
    "test_df['text'] = test_df['title']+test_df['content']\r\n",
    "# test_df = test_df.sample(frac=1).reset_index(drop=True)\r\n",
    "test_df.head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['메디안', '치석', '케어', '오리지널', '치약', 'p', '가격', '정리', '메디안', '치석', '케어', '오리지널', '치약', 'p', '리뷰', '원', '원', '메디안', '치석', '케', '어', '화이트', '치약', '리뷰', '원', '원', '더', '가깝', '게', '일단', '메디안', '치석', '케어', '오리지널', '치약', 'p', '는', '준', '수', '됐', '지', '확실히', '찍', '은', '소진', '하', '죠', '충분', '하', '지', '적의', '하', '게', '절실', '하', '고', '느낌', '드셨', '어요', '민감', '하', '므로', '흥청망청', '면봉', '을', '절묘', '하', '게', '이런', '상록', '에서', '정말', '싫', '어', '해로운', '동그라미', '를', '그야말로', '친', '고등', '학생', '룬', '빠른', '스탠드', '를', '청계', '를', '내보낸다', '순', '인맥', '을', '건축물대장', '으로서', '도', '모두', '나올', '지금', '있', '은', '통합', '됐', '고요', '곧', '받', '을', '새로', '쓴', '떨렸', '습니다', '새', '에', '적의', '하', '게', '그렇게', '뜨겁', '지', '가까이', '이르', '는', '달콤', '하', '고', '그리', '높', '지', '흔치', '않', '게', '매각', '에서', '요', '그', '보다', '다녀왔', '어요', '딱', '한', '를', '많이', '쓴', '더', '나올', '그만', '한', '가', '때때로', '앉', '을', '명확히', '를', '없이', '좋', '아', '더', '길', '다고', '바라봐야', '했', '다며', '가장', '쉽', '게', '진정', '한', '가', '건설', '대', '고', '없이', '이길', '급격히', '떨어진', '오랜', '창립', '을', '재차', '면담', '을', '확실', '하', '다면서', '재배', '하', '랄', '다', '돌려줬', '습니다', '잘', '못', '건드린', '그만큼', '나올', '커', '지', '리라', '지금', '드릴', '태교', '이란', '사실상', '추스릴', '상당히', '강하', '게', '같이', '나누', '는', '주', '었', '는가', '조금', '나아진', '마침내', '싸울', '조금', '낮', '고', '요', '못', '올', '꾸준히', '를', '바이', '델', '을', '미리', '줄', '걸', '었', '다는데']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   crawl_data_id  100 non-null    object\n",
      " 1   title          100 non-null    object\n",
      " 2   content        100 non-null    object\n",
      " 3   crawled_date   100 non-null    object\n",
      " 4   garbage        100 non-null    object\n",
      " 5   text           100 non-null    object\n",
      " 6   tokenized      100 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-23af3b76746d>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df['text'] = test_df['text'].str.replace(\"[[0-9],{0,1}([0-9],{0,3}){0,4}]\",\"price\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:160: FutureWarning: Possible nested set at position 1\n",
      "  compiled = re.compile(pat, flags=flags)\n",
      "<ipython-input-2-23af3b76746d>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df['text'] = test_df['text'].str.replace(\"[^가-힣 price]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "from eunjeon import Mecab\r\n",
    "mecab = Mecab()\r\n",
    "# [0-9],{0,1}([0-9],{0,3}){0,4}\r\n",
    "test_df['text'] = test_df['text'].str.replace(\"[[0-9],{0,1}([0-9],{0,3}){0,4}]\",\"price\")\r\n",
    "\r\n",
    "test_df['text'] = test_df['text'].str.replace(\"[^가-힣 price]\",\"\")\r\n",
    "test_df['text'] = test_df['text'].apply(mecab.morphs)\r\n",
    "test_df['tokenized'] = test_df['text'].apply(lambda x : [item for item in x if len(item) > 1 or item == '원'])\r\n",
    "print(test_df['text'].head()[4])\r\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [로레알, 파리, 엑스트라, 오디, 네리, 로즈, 헤어, 추천, 리뷰, 레알, 파리...\n",
       "1    [스타일, 플렉서블, 헤어스프레이, 추천, 비교, 스타일, 플렉서블, 헤어스프레이,...\n",
       "2    [cre, 전동, 칫솔, 호환, 칫솔, 일반, 회전, 제품, 후기, cre, 전동,...\n",
       "3    [자카, 쿠션, 스프, 라이트, 실내, 리뷰, 자카, 쿠션, 스프, 라이트, 실내,...\n",
       "4    [메디안, 치석, 케어, 오리지널, 치약, 가격, 정리, 메디안, 치석, 케어, 오...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['tokenized'].head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "\r\n",
    "tokenizer = pickle.load(open('D:/분석팀 스터디/NLP_TEST/0610/saved/conv1D_tokenizer_0614.pkl','rb'))\r\n",
    "labelencoder = pickle.load(open('D:/분석팀 스터디/NLP_TEST/0610/saved/conv1D_labelencoder_0614.pkl','rb'))\r\n",
    "model = load_model('D:/분석팀 스터디/NLP_TEST/0610/saved/conv1D_model_0614.h5')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawl_data_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>crawled_date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garbage</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         crawl_data_id  title  content  crawled_date  text  tokenized\n",
       "garbage                                                              \n",
       "0                   34     34       34            34    34         34\n",
       "1                   66     66       66            66    66         66"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['garbage'] = labelencoder.transform(test_df['garbage'])\r\n",
    "test_df.groupby(['garbage']).count()\r\n",
    "#가비지 34개 진성 66개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = test_df['tokenized']\r\n",
    "x_predict = tokenizer.texts_to_sequences(x_predict)\r\n",
    "# x_predict[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 750)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "\r\n",
    "x_predict = pad_sequences(x_predict, maxlen=750)\r\n",
    "print(x_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "result = model.predict(x_predict)\r\n",
    "result = np.argmax(result, axis=1)\r\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "answer = test_df[\"garbage\"]\r\n",
    "print(answer.shape)\r\n",
    "print(result.shape)\r\n",
    "\r\n",
    "accuracy_score(answer,result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
